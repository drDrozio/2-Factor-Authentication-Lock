{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caeeeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pycaret.classification import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4839b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = 'output/embeddings.pickle' \n",
    "recognizer = 'output/recognizer.pickle' \n",
    "le = 'output/le.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a01ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.loads(open(embeddings, \"rb\").read())\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data[\"names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7195101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.DataFrame(labels,columns=['label'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dc94017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 128)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data[\"embeddings\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c1afaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.035272</td>\n",
       "      <td>0.130549</td>\n",
       "      <td>0.077140</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.093327</td>\n",
       "      <td>0.169951</td>\n",
       "      <td>0.019327</td>\n",
       "      <td>-0.211990</td>\n",
       "      <td>0.054437</td>\n",
       "      <td>-0.057792</td>\n",
       "      <td>-0.010021</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>-0.071921</td>\n",
       "      <td>-0.047193</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>-0.017153</td>\n",
       "      <td>0.109690</td>\n",
       "      <td>-0.060444</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.048623</td>\n",
       "      <td>-0.032086</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>0.066715</td>\n",
       "      <td>0.100766</td>\n",
       "      <td>-0.044339</td>\n",
       "      <td>-0.172545</td>\n",
       "      <td>-0.068065</td>\n",
       "      <td>0.063683</td>\n",
       "      <td>0.042012</td>\n",
       "      <td>0.174813</td>\n",
       "      <td>0.214898</td>\n",
       "      <td>-0.063273</td>\n",
       "      <td>0.036166</td>\n",
       "      <td>0.131680</td>\n",
       "      <td>0.105793</td>\n",
       "      <td>-0.009939</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.014088</td>\n",
       "      <td>-0.138872</td>\n",
       "      <td>0.107497</td>\n",
       "      <td>-0.034685</td>\n",
       "      <td>0.017678</td>\n",
       "      <td>-0.079311</td>\n",
       "      <td>-0.039174</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.065180</td>\n",
       "      <td>0.024870</td>\n",
       "      <td>-0.111402</td>\n",
       "      <td>-0.089333</td>\n",
       "      <td>-0.032827</td>\n",
       "      <td>0.038684</td>\n",
       "      <td>0.100456</td>\n",
       "      <td>-0.108618</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>-0.080496</td>\n",
       "      <td>0.102502</td>\n",
       "      <td>-0.078720</td>\n",
       "      <td>-0.039908</td>\n",
       "      <td>-0.133791</td>\n",
       "      <td>0.079861</td>\n",
       "      <td>0.118002</td>\n",
       "      <td>-0.219331</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.149613</td>\n",
       "      <td>0.018380</td>\n",
       "      <td>-0.079519</td>\n",
       "      <td>-0.226750</td>\n",
       "      <td>0.219220</td>\n",
       "      <td>-0.002438</td>\n",
       "      <td>0.060006</td>\n",
       "      <td>-0.047680</td>\n",
       "      <td>0.043841</td>\n",
       "      <td>-0.011846</td>\n",
       "      <td>-0.032531</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>-0.033843</td>\n",
       "      <td>-0.034221</td>\n",
       "      <td>-0.076183</td>\n",
       "      <td>-0.049527</td>\n",
       "      <td>0.148277</td>\n",
       "      <td>-0.048198</td>\n",
       "      <td>-0.069902</td>\n",
       "      <td>-0.008755</td>\n",
       "      <td>-0.081842</td>\n",
       "      <td>-0.037609</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>-0.096942</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.151702</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.029965</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.051718</td>\n",
       "      <td>0.031223</td>\n",
       "      <td>0.030321</td>\n",
       "      <td>0.027803</td>\n",
       "      <td>-0.030333</td>\n",
       "      <td>-0.102875</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.007965</td>\n",
       "      <td>0.124052</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>-0.056101</td>\n",
       "      <td>0.089242</td>\n",
       "      <td>0.036035</td>\n",
       "      <td>-0.063014</td>\n",
       "      <td>0.059906</td>\n",
       "      <td>-0.025702</td>\n",
       "      <td>-0.033035</td>\n",
       "      <td>0.153168</td>\n",
       "      <td>-0.083587</td>\n",
       "      <td>-0.096939</td>\n",
       "      <td>-0.029184</td>\n",
       "      <td>0.111759</td>\n",
       "      <td>0.117374</td>\n",
       "      <td>0.105229</td>\n",
       "      <td>-0.004897</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>0.040184</td>\n",
       "      <td>0.144834</td>\n",
       "      <td>0.111718</td>\n",
       "      <td>-0.076591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>0.058970</td>\n",
       "      <td>0.096895</td>\n",
       "      <td>0.122813</td>\n",
       "      <td>0.188039</td>\n",
       "      <td>0.043433</td>\n",
       "      <td>-0.158121</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>-0.050044</td>\n",
       "      <td>-0.012845</td>\n",
       "      <td>0.017861</td>\n",
       "      <td>-0.038108</td>\n",
       "      <td>-0.037544</td>\n",
       "      <td>0.068805</td>\n",
       "      <td>-0.005508</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.096823</td>\n",
       "      <td>-0.051021</td>\n",
       "      <td>0.039063</td>\n",
       "      <td>0.051065</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>0.062075</td>\n",
       "      <td>-0.017273</td>\n",
       "      <td>-0.187854</td>\n",
       "      <td>-0.106254</td>\n",
       "      <td>0.102360</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.143472</td>\n",
       "      <td>0.213258</td>\n",
       "      <td>-0.077684</td>\n",
       "      <td>0.032859</td>\n",
       "      <td>0.140599</td>\n",
       "      <td>0.123597</td>\n",
       "      <td>-0.003343</td>\n",
       "      <td>0.041470</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>-0.151590</td>\n",
       "      <td>0.103914</td>\n",
       "      <td>-0.025220</td>\n",
       "      <td>-0.030871</td>\n",
       "      <td>-0.055424</td>\n",
       "      <td>-0.087358</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>-0.143604</td>\n",
       "      <td>-0.093024</td>\n",
       "      <td>-0.067700</td>\n",
       "      <td>0.056087</td>\n",
       "      <td>0.076622</td>\n",
       "      <td>-0.100785</td>\n",
       "      <td>0.051694</td>\n",
       "      <td>0.061550</td>\n",
       "      <td>-0.074530</td>\n",
       "      <td>0.121136</td>\n",
       "      <td>-0.079973</td>\n",
       "      <td>-0.036893</td>\n",
       "      <td>-0.130991</td>\n",
       "      <td>0.080879</td>\n",
       "      <td>0.145354</td>\n",
       "      <td>-0.217525</td>\n",
       "      <td>0.192016</td>\n",
       "      <td>0.116015</td>\n",
       "      <td>0.026780</td>\n",
       "      <td>-0.046939</td>\n",
       "      <td>-0.186351</td>\n",
       "      <td>0.200661</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>0.057910</td>\n",
       "      <td>-0.051445</td>\n",
       "      <td>0.030659</td>\n",
       "      <td>-0.018814</td>\n",
       "      <td>-0.026948</td>\n",
       "      <td>-0.019063</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>-0.072511</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.149421</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.081038</td>\n",
       "      <td>0.017822</td>\n",
       "      <td>-0.090807</td>\n",
       "      <td>-0.013773</td>\n",
       "      <td>0.020706</td>\n",
       "      <td>-0.094571</td>\n",
       "      <td>0.136814</td>\n",
       "      <td>0.200194</td>\n",
       "      <td>-0.023944</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.053508</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>0.039845</td>\n",
       "      <td>0.058532</td>\n",
       "      <td>0.031982</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>-0.095680</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>-0.064665</td>\n",
       "      <td>0.126307</td>\n",
       "      <td>0.084505</td>\n",
       "      <td>-0.040794</td>\n",
       "      <td>0.125780</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>-0.023849</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>-0.057076</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>0.161704</td>\n",
       "      <td>-0.063596</td>\n",
       "      <td>-0.110260</td>\n",
       "      <td>-0.100536</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>0.117124</td>\n",
       "      <td>0.093818</td>\n",
       "      <td>-0.016990</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.036724</td>\n",
       "      <td>0.130144</td>\n",
       "      <td>0.112965</td>\n",
       "      <td>-0.088067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008680</td>\n",
       "      <td>0.077453</td>\n",
       "      <td>0.131348</td>\n",
       "      <td>0.191128</td>\n",
       "      <td>0.121031</td>\n",
       "      <td>0.106188</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>-0.251341</td>\n",
       "      <td>0.064199</td>\n",
       "      <td>-0.070962</td>\n",
       "      <td>-0.041673</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>-0.103942</td>\n",
       "      <td>-0.054502</td>\n",
       "      <td>-0.025733</td>\n",
       "      <td>0.035421</td>\n",
       "      <td>0.063912</td>\n",
       "      <td>0.132785</td>\n",
       "      <td>-0.088546</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.025689</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>-0.013508</td>\n",
       "      <td>0.126071</td>\n",
       "      <td>0.091036</td>\n",
       "      <td>-0.038070</td>\n",
       "      <td>-0.115734</td>\n",
       "      <td>-0.033033</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>0.053002</td>\n",
       "      <td>0.108451</td>\n",
       "      <td>0.241375</td>\n",
       "      <td>-0.066919</td>\n",
       "      <td>0.064121</td>\n",
       "      <td>0.119584</td>\n",
       "      <td>0.043746</td>\n",
       "      <td>0.016569</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>-0.012097</td>\n",
       "      <td>-0.140013</td>\n",
       "      <td>0.095810</td>\n",
       "      <td>-0.008010</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>-0.147377</td>\n",
       "      <td>0.014818</td>\n",
       "      <td>0.032224</td>\n",
       "      <td>0.035720</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>-0.070003</td>\n",
       "      <td>-0.067015</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.120319</td>\n",
       "      <td>-0.103381</td>\n",
       "      <td>0.070179</td>\n",
       "      <td>0.049763</td>\n",
       "      <td>-0.055351</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>-0.029360</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>-0.041246</td>\n",
       "      <td>0.071486</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>-0.186270</td>\n",
       "      <td>0.185819</td>\n",
       "      <td>0.077620</td>\n",
       "      <td>-0.008904</td>\n",
       "      <td>-0.074662</td>\n",
       "      <td>-0.221968</td>\n",
       "      <td>0.245726</td>\n",
       "      <td>-0.025832</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>-0.024986</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>-0.056481</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.056593</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>-0.057933</td>\n",
       "      <td>-0.105674</td>\n",
       "      <td>-0.021532</td>\n",
       "      <td>0.184066</td>\n",
       "      <td>-0.044799</td>\n",
       "      <td>-0.068935</td>\n",
       "      <td>0.025048</td>\n",
       "      <td>-0.127605</td>\n",
       "      <td>-0.042532</td>\n",
       "      <td>0.026277</td>\n",
       "      <td>-0.154930</td>\n",
       "      <td>0.144564</td>\n",
       "      <td>0.084444</td>\n",
       "      <td>-0.002322</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.050441</td>\n",
       "      <td>0.046345</td>\n",
       "      <td>0.113182</td>\n",
       "      <td>0.024419</td>\n",
       "      <td>-0.008747</td>\n",
       "      <td>0.072855</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>-0.029965</td>\n",
       "      <td>-0.116127</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.043126</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>0.080347</td>\n",
       "      <td>-0.089660</td>\n",
       "      <td>0.020163</td>\n",
       "      <td>0.047002</td>\n",
       "      <td>-0.072680</td>\n",
       "      <td>0.067946</td>\n",
       "      <td>0.035044</td>\n",
       "      <td>-0.019937</td>\n",
       "      <td>0.120608</td>\n",
       "      <td>-0.101364</td>\n",
       "      <td>-0.137912</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.018459</td>\n",
       "      <td>0.079504</td>\n",
       "      <td>0.077039</td>\n",
       "      <td>0.087828</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>0.080625</td>\n",
       "      <td>0.147510</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>-0.155312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.019782</td>\n",
       "      <td>0.061066</td>\n",
       "      <td>0.139594</td>\n",
       "      <td>0.206417</td>\n",
       "      <td>0.116256</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>0.018090</td>\n",
       "      <td>-0.245630</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>-0.077583</td>\n",
       "      <td>-0.047773</td>\n",
       "      <td>0.096026</td>\n",
       "      <td>-0.106044</td>\n",
       "      <td>-0.056108</td>\n",
       "      <td>-0.023072</td>\n",
       "      <td>0.027942</td>\n",
       "      <td>0.044348</td>\n",
       "      <td>0.115745</td>\n",
       "      <td>-0.086459</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>-0.020127</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>0.114428</td>\n",
       "      <td>0.096118</td>\n",
       "      <td>-0.029952</td>\n",
       "      <td>-0.146812</td>\n",
       "      <td>-0.052308</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.028710</td>\n",
       "      <td>0.125852</td>\n",
       "      <td>0.252585</td>\n",
       "      <td>-0.075572</td>\n",
       "      <td>0.052082</td>\n",
       "      <td>0.111578</td>\n",
       "      <td>0.046535</td>\n",
       "      <td>-0.008938</td>\n",
       "      <td>0.022726</td>\n",
       "      <td>-0.021837</td>\n",
       "      <td>-0.142620</td>\n",
       "      <td>0.110166</td>\n",
       "      <td>-0.003278</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>-0.151967</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.027358</td>\n",
       "      <td>0.025690</td>\n",
       "      <td>-0.006603</td>\n",
       "      <td>-0.057421</td>\n",
       "      <td>-0.082976</td>\n",
       "      <td>0.052417</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>0.131045</td>\n",
       "      <td>-0.112021</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.042482</td>\n",
       "      <td>-0.045618</td>\n",
       "      <td>0.058797</td>\n",
       "      <td>-0.031600</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>-0.053165</td>\n",
       "      <td>0.078706</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>-0.178607</td>\n",
       "      <td>0.198054</td>\n",
       "      <td>0.097675</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>-0.075668</td>\n",
       "      <td>-0.213914</td>\n",
       "      <td>0.233447</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>0.056969</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>0.043172</td>\n",
       "      <td>-0.043475</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>-0.010173</td>\n",
       "      <td>-0.052258</td>\n",
       "      <td>-0.087504</td>\n",
       "      <td>-0.040594</td>\n",
       "      <td>0.164556</td>\n",
       "      <td>-0.044794</td>\n",
       "      <td>-0.079000</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>-0.135797</td>\n",
       "      <td>-0.027073</td>\n",
       "      <td>0.042360</td>\n",
       "      <td>-0.157430</td>\n",
       "      <td>0.110299</td>\n",
       "      <td>0.097369</td>\n",
       "      <td>0.018381</td>\n",
       "      <td>0.042513</td>\n",
       "      <td>0.038726</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>0.094327</td>\n",
       "      <td>0.035264</td>\n",
       "      <td>-0.006044</td>\n",
       "      <td>0.073479</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>-0.039664</td>\n",
       "      <td>-0.115224</td>\n",
       "      <td>0.037572</td>\n",
       "      <td>0.043544</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.097423</td>\n",
       "      <td>-0.075610</td>\n",
       "      <td>0.057016</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>-0.080747</td>\n",
       "      <td>0.083867</td>\n",
       "      <td>0.021393</td>\n",
       "      <td>-0.036198</td>\n",
       "      <td>0.135939</td>\n",
       "      <td>-0.089753</td>\n",
       "      <td>-0.141790</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.084474</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>0.087021</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>-0.046037</td>\n",
       "      <td>0.070553</td>\n",
       "      <td>0.159270</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>-0.137247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.138728</td>\n",
       "      <td>0.166614</td>\n",
       "      <td>0.118090</td>\n",
       "      <td>0.140926</td>\n",
       "      <td>0.045724</td>\n",
       "      <td>-0.198802</td>\n",
       "      <td>0.057802</td>\n",
       "      <td>-0.073293</td>\n",
       "      <td>-0.010740</td>\n",
       "      <td>0.070541</td>\n",
       "      <td>-0.060235</td>\n",
       "      <td>-0.055368</td>\n",
       "      <td>0.021582</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>0.031918</td>\n",
       "      <td>0.099286</td>\n",
       "      <td>-0.119065</td>\n",
       "      <td>0.034156</td>\n",
       "      <td>0.059723</td>\n",
       "      <td>-0.014180</td>\n",
       "      <td>-0.024863</td>\n",
       "      <td>0.135118</td>\n",
       "      <td>0.086580</td>\n",
       "      <td>-0.048994</td>\n",
       "      <td>-0.171696</td>\n",
       "      <td>-0.063384</td>\n",
       "      <td>0.046831</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>0.224003</td>\n",
       "      <td>-0.078025</td>\n",
       "      <td>0.078427</td>\n",
       "      <td>0.108445</td>\n",
       "      <td>0.077220</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>-0.012248</td>\n",
       "      <td>-0.133006</td>\n",
       "      <td>0.115697</td>\n",
       "      <td>-0.019387</td>\n",
       "      <td>0.020633</td>\n",
       "      <td>-0.133306</td>\n",
       "      <td>-0.006120</td>\n",
       "      <td>0.017825</td>\n",
       "      <td>0.045603</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>-0.096419</td>\n",
       "      <td>-0.084369</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.093408</td>\n",
       "      <td>-0.096985</td>\n",
       "      <td>0.087690</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>-0.094216</td>\n",
       "      <td>0.093959</td>\n",
       "      <td>-0.056029</td>\n",
       "      <td>-0.021463</td>\n",
       "      <td>-0.101621</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.046305</td>\n",
       "      <td>-0.218398</td>\n",
       "      <td>0.186437</td>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>-0.065277</td>\n",
       "      <td>-0.235277</td>\n",
       "      <td>0.210155</td>\n",
       "      <td>-0.008403</td>\n",
       "      <td>0.057485</td>\n",
       "      <td>-0.042596</td>\n",
       "      <td>0.028152</td>\n",
       "      <td>-0.011543</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.039083</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>-0.019877</td>\n",
       "      <td>-0.061042</td>\n",
       "      <td>-0.039041</td>\n",
       "      <td>0.152874</td>\n",
       "      <td>-0.029120</td>\n",
       "      <td>-0.074790</td>\n",
       "      <td>0.013488</td>\n",
       "      <td>-0.103170</td>\n",
       "      <td>-0.006594</td>\n",
       "      <td>0.032708</td>\n",
       "      <td>-0.130670</td>\n",
       "      <td>0.140979</td>\n",
       "      <td>0.124134</td>\n",
       "      <td>-0.044064</td>\n",
       "      <td>0.024188</td>\n",
       "      <td>0.048129</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.063262</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.056573</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.051009</td>\n",
       "      <td>-0.027118</td>\n",
       "      <td>-0.130354</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.074871</td>\n",
       "      <td>0.076887</td>\n",
       "      <td>-0.065854</td>\n",
       "      <td>0.076868</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>-0.075561</td>\n",
       "      <td>0.085687</td>\n",
       "      <td>-0.023691</td>\n",
       "      <td>-0.019356</td>\n",
       "      <td>0.159712</td>\n",
       "      <td>-0.065752</td>\n",
       "      <td>-0.145987</td>\n",
       "      <td>-0.010764</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.116921</td>\n",
       "      <td>0.074511</td>\n",
       "      <td>0.056087</td>\n",
       "      <td>-0.001586</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.071556</td>\n",
       "      <td>0.164989</td>\n",
       "      <td>0.089884</td>\n",
       "      <td>-0.132333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.035272  0.130549  0.077140  0.143200  0.093327  0.169951  0.019327   \n",
       "1  0.004426  0.107973  0.058970  0.096895  0.122813  0.188039  0.043433   \n",
       "2 -0.008680  0.077453  0.131348  0.191128  0.121031  0.106188  0.002600   \n",
       "3 -0.019782  0.061066  0.139594  0.206417  0.116256  0.097216  0.018090   \n",
       "4  0.000088  0.092300  0.138728  0.166614  0.118090  0.140926  0.045724   \n",
       "\n",
       "        7         8         9         10        11        12        13   \\\n",
       "0 -0.211990  0.054437 -0.057792 -0.010021  0.034464 -0.071921 -0.047193   \n",
       "1 -0.158121 -0.001830 -0.050044 -0.012845  0.017861 -0.038108 -0.037544   \n",
       "2 -0.251341  0.064199 -0.070962 -0.041673  0.097439 -0.103942 -0.054502   \n",
       "3 -0.245630  0.061797 -0.077583 -0.047773  0.096026 -0.106044 -0.056108   \n",
       "4 -0.198802  0.057802 -0.073293 -0.010740  0.070541 -0.060235 -0.055368   \n",
       "\n",
       "        14        15        16        17        18        19        20   \\\n",
       "0  0.022213  0.011982 -0.017153  0.109690 -0.060444  0.003125  0.048623   \n",
       "1  0.068805 -0.005508  0.006983  0.096823 -0.051021  0.039063  0.051065   \n",
       "2 -0.025733  0.035421  0.063912  0.132785 -0.088546  0.010747  0.025689   \n",
       "3 -0.023072  0.027942  0.044348  0.115745 -0.086459  0.022031  0.025796   \n",
       "4  0.021582  0.022751  0.031918  0.099286 -0.119065  0.034156  0.059723   \n",
       "\n",
       "        21        22        23        24        25        26        27   \\\n",
       "0 -0.032086 -0.004956  0.066715  0.100766 -0.044339 -0.172545 -0.068065   \n",
       "1  0.000785  0.000163  0.055347  0.062075 -0.017273 -0.187854 -0.106254   \n",
       "2  0.011797 -0.013508  0.126071  0.091036 -0.038070 -0.115734 -0.033033   \n",
       "3 -0.020127 -0.004205  0.114428  0.096118 -0.029952 -0.146812 -0.052308   \n",
       "4 -0.014180 -0.024863  0.135118  0.086580 -0.048994 -0.171696 -0.063384   \n",
       "\n",
       "        28        29        30        31        32        33        34   \\\n",
       "0  0.063683  0.042012  0.174813  0.214898 -0.063273  0.036166  0.131680   \n",
       "1  0.102360  0.029837  0.143472  0.213258 -0.077684  0.032859  0.140599   \n",
       "2 -0.000475  0.053002  0.108451  0.241375 -0.066919  0.064121  0.119584   \n",
       "3  0.011330  0.028710  0.125852  0.252585 -0.075572  0.052082  0.111578   \n",
       "4  0.046831  0.042688  0.140128  0.224003 -0.078025  0.078427  0.108445   \n",
       "\n",
       "        35        36        37        38        39        40        41   \\\n",
       "0  0.105793 -0.009939  0.011038  0.014088 -0.138872  0.107497 -0.034685   \n",
       "1  0.123597 -0.003343  0.041470  0.003392 -0.151590  0.103914 -0.025220   \n",
       "2  0.043746  0.016569 -0.010280 -0.012097 -0.140013  0.095810 -0.008010   \n",
       "3  0.046535 -0.008938  0.022726 -0.021837 -0.142620  0.110166 -0.003278   \n",
       "4  0.077220  0.008760  0.036718 -0.012248 -0.133006  0.115697 -0.019387   \n",
       "\n",
       "        42        43        44        45        46        47        48   \\\n",
       "0  0.017678 -0.079311 -0.039174  0.002101  0.065180  0.024870 -0.111402   \n",
       "1 -0.030871 -0.055424 -0.087358  0.073536  0.074200  0.048052 -0.143604   \n",
       "2  0.053952 -0.147377  0.014818  0.032224  0.035720  0.001760 -0.070003   \n",
       "3  0.021749 -0.151967  0.005673  0.027358  0.025690 -0.006603 -0.057421   \n",
       "4  0.020633 -0.133306 -0.006120  0.017825  0.045603  0.008425 -0.096419   \n",
       "\n",
       "        49        50        51        52        53        54        55   \\\n",
       "0 -0.089333 -0.032827  0.038684  0.100456 -0.108618  0.047423  0.084215   \n",
       "1 -0.093024 -0.067700  0.056087  0.076622 -0.100785  0.051694  0.061550   \n",
       "2 -0.067015  0.086723  0.009589  0.120319 -0.103381  0.070179  0.049763   \n",
       "3 -0.082976  0.052417  0.020026  0.131045 -0.112021  0.069952  0.042482   \n",
       "4 -0.084369  0.024127  0.021329  0.093408 -0.096985  0.087690  0.060606   \n",
       "\n",
       "        56        57        58        59        60        61        62   \\\n",
       "0 -0.080496  0.102502 -0.078720 -0.039908 -0.133791  0.079861  0.118002   \n",
       "1 -0.074530  0.121136 -0.079973 -0.036893 -0.130991  0.080879  0.145354   \n",
       "2 -0.055351  0.050172 -0.029360  0.003330 -0.041246  0.071486  0.001772   \n",
       "3 -0.045618  0.058797 -0.031600  0.003527 -0.053165  0.078706  0.006715   \n",
       "4 -0.094216  0.093959 -0.056029 -0.021463 -0.101621  0.064102  0.046305   \n",
       "\n",
       "        63        64        65        66        67        68        69   \\\n",
       "0 -0.219331  0.187771  0.149613  0.018380 -0.079519 -0.226750  0.219220   \n",
       "1 -0.217525  0.192016  0.116015  0.026780 -0.046939 -0.186351  0.200661   \n",
       "2 -0.186270  0.185819  0.077620 -0.008904 -0.074662 -0.221968  0.245726   \n",
       "3 -0.178607  0.198054  0.097675  0.006977 -0.075668 -0.213914  0.233447   \n",
       "4 -0.218398  0.186437  0.120093  0.015809 -0.065277 -0.235277  0.210155   \n",
       "\n",
       "        70        71        72        73        74        75        76   \\\n",
       "0 -0.002438  0.060006 -0.047680  0.043841 -0.011846 -0.032531  0.008418   \n",
       "1  0.008283  0.057910 -0.051445  0.030659 -0.018814 -0.026948 -0.019063   \n",
       "2 -0.025832  0.041231 -0.024986  0.013114 -0.056481  0.013851  0.056593   \n",
       "3 -0.022400  0.056969 -0.017587  0.043172 -0.043475  0.002365  0.044008   \n",
       "4 -0.008403  0.057485 -0.042596  0.028152 -0.011543  0.007149  0.039083   \n",
       "\n",
       "        77        78        79        80        81        82        83   \\\n",
       "0 -0.033843 -0.034221 -0.076183 -0.049527  0.148277 -0.048198 -0.069902   \n",
       "1 -0.000615  0.003193 -0.072511 -0.043729  0.149421 -0.067831 -0.081038   \n",
       "2  0.003192 -0.057933 -0.105674 -0.021532  0.184066 -0.044799 -0.068935   \n",
       "3 -0.010173 -0.052258 -0.087504 -0.040594  0.164556 -0.044794 -0.079000   \n",
       "4  0.011152 -0.019877 -0.061042 -0.039041  0.152874 -0.029120 -0.074790   \n",
       "\n",
       "        84        85        86        87        88        89        90   \\\n",
       "0 -0.008755 -0.081842 -0.037609  0.011747 -0.096942  0.123732  0.151702   \n",
       "1  0.017822 -0.090807 -0.013773  0.020706 -0.094571  0.136814  0.200194   \n",
       "2  0.025048 -0.127605 -0.042532  0.026277 -0.154930  0.144564  0.084444   \n",
       "3  0.022960 -0.135797 -0.027073  0.042360 -0.157430  0.110299  0.097369   \n",
       "4  0.013488 -0.103170 -0.006594  0.032708 -0.130670  0.140979  0.124134   \n",
       "\n",
       "        91        92        93        94        95        96        97   \\\n",
       "0 -0.037939  0.014830  0.015078  0.070270  0.029965  0.004236  0.051718   \n",
       "1 -0.023944 -0.010411  0.014633  0.053508 -0.004719  0.039845  0.058532   \n",
       "2 -0.002322  0.025327  0.050441  0.046345  0.113182  0.024419 -0.008747   \n",
       "3  0.018381  0.042513  0.038726  0.044484  0.094327  0.035264 -0.006044   \n",
       "4 -0.044064  0.024188  0.048129  0.020598  0.063262  0.020546 -0.009154   \n",
       "\n",
       "        98        99        100       101       102       103       104  \\\n",
       "0  0.031223  0.030321  0.027803 -0.030333 -0.102875 -0.000222 -0.007965   \n",
       "1  0.031982  0.006289  0.028769  0.001299 -0.095680 -0.007935 -0.064665   \n",
       "2  0.072855  0.015001  0.068900 -0.029965 -0.116127  0.043597  0.043126   \n",
       "3  0.073479  0.020070  0.059361 -0.039664 -0.115224  0.037572  0.043544   \n",
       "4  0.056573  0.021480  0.051009 -0.027118 -0.130354  0.048790  0.001899   \n",
       "\n",
       "        105       106       107       108       109       110       111  \\\n",
       "0  0.124052  0.097954 -0.056101  0.089242  0.036035 -0.063014  0.059906   \n",
       "1  0.126307  0.084505 -0.040794  0.125780  0.031149 -0.023849  0.069360   \n",
       "2  0.015344  0.080347 -0.089660  0.020163  0.047002 -0.072680  0.067946   \n",
       "3  0.026665  0.097423 -0.075610  0.057016  0.044589 -0.080747  0.083867   \n",
       "4  0.074871  0.076887 -0.065854  0.076868  0.009272 -0.075561  0.085687   \n",
       "\n",
       "        112       113       114       115       116       117       118  \\\n",
       "0 -0.025702 -0.033035  0.153168 -0.083587 -0.096939 -0.029184  0.111759   \n",
       "1 -0.057076 -0.050838  0.161704 -0.063596 -0.110260 -0.100536  0.090660   \n",
       "2  0.035044 -0.019937  0.120608 -0.101364 -0.137912  0.004266  0.018459   \n",
       "3  0.021393 -0.036198  0.135939 -0.089753 -0.141790  0.004591  0.033399   \n",
       "4 -0.023691 -0.019356  0.159712 -0.065752 -0.145987 -0.010764  0.028924   \n",
       "\n",
       "        119       120       121       122       123       124       125  \\\n",
       "0  0.117374  0.105229 -0.004897  0.009422  0.008704  0.040184  0.144834   \n",
       "1  0.117124  0.093818 -0.016990  0.027945  0.055558  0.036724  0.130144   \n",
       "2  0.079504  0.077039  0.087828  0.003502 -0.048885  0.080625  0.147510   \n",
       "3  0.084474  0.059810  0.087021 -0.007595 -0.046037  0.070553  0.159270   \n",
       "4  0.116921  0.074511  0.056087 -0.001586  0.009893  0.071556  0.164989   \n",
       "\n",
       "        126       127  \n",
       "0  0.111718 -0.076591  \n",
       "1  0.112965 -0.088067  \n",
       "2  0.068720 -0.155312  \n",
       "3  0.067416 -0.137247  \n",
       "4  0.089884 -0.132333  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a17cf315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.054610</td>\n",
       "      <td>0.104350</td>\n",
       "      <td>-0.004463</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>0.084425</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.116126</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.022170</td>\n",
       "      <td>-0.033977</td>\n",
       "      <td>0.041059</td>\n",
       "      <td>0.045683</td>\n",
       "      <td>0.042052</td>\n",
       "      <td>-0.185606</td>\n",
       "      <td>0.110666</td>\n",
       "      <td>-0.029643</td>\n",
       "      <td>-0.039188</td>\n",
       "      <td>0.066859</td>\n",
       "      <td>-0.137303</td>\n",
       "      <td>-0.008230</td>\n",
       "      <td>0.081344</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.149097</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>-0.200024</td>\n",
       "      <td>-0.145016</td>\n",
       "      <td>-0.179111</td>\n",
       "      <td>-0.026356</td>\n",
       "      <td>0.061489</td>\n",
       "      <td>0.149903</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>-0.084600</td>\n",
       "      <td>0.146129</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.057449</td>\n",
       "      <td>-0.098072</td>\n",
       "      <td>-0.020586</td>\n",
       "      <td>0.052420</td>\n",
       "      <td>0.181609</td>\n",
       "      <td>-0.089893</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>0.035239</td>\n",
       "      <td>-0.134608</td>\n",
       "      <td>-0.140755</td>\n",
       "      <td>0.096062</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>-0.046492</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.101022</td>\n",
       "      <td>-0.151087</td>\n",
       "      <td>-0.073661</td>\n",
       "      <td>-0.022995</td>\n",
       "      <td>-0.010991</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>-0.081251</td>\n",
       "      <td>0.092768</td>\n",
       "      <td>0.022553</td>\n",
       "      <td>-0.003308</td>\n",
       "      <td>-0.151577</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.015049</td>\n",
       "      <td>-0.288440</td>\n",
       "      <td>0.084030</td>\n",
       "      <td>-0.045042</td>\n",
       "      <td>0.058321</td>\n",
       "      <td>-0.130605</td>\n",
       "      <td>-0.180030</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>-0.027518</td>\n",
       "      <td>0.127077</td>\n",
       "      <td>-0.050003</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>-0.002756</td>\n",
       "      <td>-0.014882</td>\n",
       "      <td>-0.013859</td>\n",
       "      <td>0.038555</td>\n",
       "      <td>-0.039611</td>\n",
       "      <td>0.073339</td>\n",
       "      <td>-0.052120</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>0.109169</td>\n",
       "      <td>0.074794</td>\n",
       "      <td>-0.116043</td>\n",
       "      <td>-0.124074</td>\n",
       "      <td>0.034347</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>-0.176807</td>\n",
       "      <td>-0.069833</td>\n",
       "      <td>-0.089236</td>\n",
       "      <td>-0.061160</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.067469</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.050246</td>\n",
       "      <td>0.084158</td>\n",
       "      <td>-0.054110</td>\n",
       "      <td>-0.028554</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>0.157867</td>\n",
       "      <td>-0.022253</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>-0.048080</td>\n",
       "      <td>0.097035</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>-0.077314</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>-0.039799</td>\n",
       "      <td>-0.031165</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.018264</td>\n",
       "      <td>-0.008749</td>\n",
       "      <td>-0.011160</td>\n",
       "      <td>0.016747</td>\n",
       "      <td>0.171894</td>\n",
       "      <td>0.128862</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>-0.054098</td>\n",
       "      <td>0.140353</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>-0.037920</td>\n",
       "      <td>-0.035048</td>\n",
       "      <td>-0.009189</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.032987</td>\n",
       "      <td>0.163666</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.111123</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0.212792</td>\n",
       "      <td>0.087295</td>\n",
       "      <td>-0.095633</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.021708</td>\n",
       "      <td>0.074333</td>\n",
       "      <td>-0.021175</td>\n",
       "      <td>-0.130598</td>\n",
       "      <td>0.118786</td>\n",
       "      <td>-0.033402</td>\n",
       "      <td>0.044143</td>\n",
       "      <td>0.101245</td>\n",
       "      <td>-0.056982</td>\n",
       "      <td>-0.024023</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>-0.005566</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.116470</td>\n",
       "      <td>-0.147236</td>\n",
       "      <td>-0.119256</td>\n",
       "      <td>-0.082188</td>\n",
       "      <td>-0.008614</td>\n",
       "      <td>0.084957</td>\n",
       "      <td>0.131567</td>\n",
       "      <td>0.177329</td>\n",
       "      <td>-0.059155</td>\n",
       "      <td>0.138054</td>\n",
       "      <td>0.044365</td>\n",
       "      <td>0.019384</td>\n",
       "      <td>0.086945</td>\n",
       "      <td>-0.108362</td>\n",
       "      <td>0.030022</td>\n",
       "      <td>-0.021587</td>\n",
       "      <td>0.175284</td>\n",
       "      <td>-0.084616</td>\n",
       "      <td>0.117992</td>\n",
       "      <td>-0.036376</td>\n",
       "      <td>-0.119377</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.107658</td>\n",
       "      <td>-0.005579</td>\n",
       "      <td>-0.072541</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.141467</td>\n",
       "      <td>-0.050046</td>\n",
       "      <td>-0.042476</td>\n",
       "      <td>-0.053328</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>0.097934</td>\n",
       "      <td>-0.112352</td>\n",
       "      <td>0.078655</td>\n",
       "      <td>-0.016129</td>\n",
       "      <td>0.025090</td>\n",
       "      <td>-0.150243</td>\n",
       "      <td>-0.003288</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>-0.325079</td>\n",
       "      <td>0.147143</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>-0.130750</td>\n",
       "      <td>-0.260288</td>\n",
       "      <td>0.164305</td>\n",
       "      <td>-0.038398</td>\n",
       "      <td>0.119548</td>\n",
       "      <td>-0.070153</td>\n",
       "      <td>0.059296</td>\n",
       "      <td>-0.011169</td>\n",
       "      <td>-0.003433</td>\n",
       "      <td>0.056143</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.030353</td>\n",
       "      <td>-0.083725</td>\n",
       "      <td>0.077166</td>\n",
       "      <td>0.037381</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>-0.008114</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>-0.086195</td>\n",
       "      <td>-0.082559</td>\n",
       "      <td>0.106784</td>\n",
       "      <td>0.041285</td>\n",
       "      <td>-0.136420</td>\n",
       "      <td>-0.042003</td>\n",
       "      <td>-0.041972</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>-0.018407</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>-0.065184</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>-0.027177</td>\n",
       "      <td>0.141740</td>\n",
       "      <td>-0.026051</td>\n",
       "      <td>0.048409</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>0.032745</td>\n",
       "      <td>-0.056513</td>\n",
       "      <td>0.029282</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>-0.021595</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.065029</td>\n",
       "      <td>-0.123813</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>-0.043564</td>\n",
       "      <td>0.074258</td>\n",
       "      <td>0.172774</td>\n",
       "      <td>0.173673</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>-0.009477</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.077578</td>\n",
       "      <td>-0.001269</td>\n",
       "      <td>0.061320</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.140201</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.119405</td>\n",
       "      <td>0.110534</td>\n",
       "      <td>0.224276</td>\n",
       "      <td>0.097438</td>\n",
       "      <td>-0.074569</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.069713</td>\n",
       "      <td>-0.009179</td>\n",
       "      <td>-0.153526</td>\n",
       "      <td>0.124314</td>\n",
       "      <td>-0.013813</td>\n",
       "      <td>0.030834</td>\n",
       "      <td>0.097384</td>\n",
       "      <td>-0.082183</td>\n",
       "      <td>-0.024574</td>\n",
       "      <td>0.034190</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>0.141087</td>\n",
       "      <td>0.110666</td>\n",
       "      <td>-0.162153</td>\n",
       "      <td>-0.136644</td>\n",
       "      <td>-0.121699</td>\n",
       "      <td>-0.010928</td>\n",
       "      <td>0.077683</td>\n",
       "      <td>0.148342</td>\n",
       "      <td>0.173177</td>\n",
       "      <td>-0.072420</td>\n",
       "      <td>0.145317</td>\n",
       "      <td>0.038170</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.078478</td>\n",
       "      <td>-0.105152</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>-0.002050</td>\n",
       "      <td>0.180953</td>\n",
       "      <td>-0.078466</td>\n",
       "      <td>0.097529</td>\n",
       "      <td>-0.034858</td>\n",
       "      <td>-0.109210</td>\n",
       "      <td>-0.100710</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>-0.012674</td>\n",
       "      <td>-0.066858</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.144579</td>\n",
       "      <td>-0.086460</td>\n",
       "      <td>-0.032010</td>\n",
       "      <td>-0.054449</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.096662</td>\n",
       "      <td>-0.093518</td>\n",
       "      <td>0.085893</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.018282</td>\n",
       "      <td>-0.153094</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>-0.326613</td>\n",
       "      <td>0.134978</td>\n",
       "      <td>0.022508</td>\n",
       "      <td>0.028558</td>\n",
       "      <td>-0.138046</td>\n",
       "      <td>-0.248304</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>-0.043949</td>\n",
       "      <td>0.128050</td>\n",
       "      <td>-0.067901</td>\n",
       "      <td>0.051206</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>-0.005614</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>-0.046669</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-0.067419</td>\n",
       "      <td>0.067974</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.012585</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>-0.097305</td>\n",
       "      <td>-0.114879</td>\n",
       "      <td>0.083355</td>\n",
       "      <td>0.040495</td>\n",
       "      <td>-0.133043</td>\n",
       "      <td>-0.051679</td>\n",
       "      <td>-0.043090</td>\n",
       "      <td>-0.010320</td>\n",
       "      <td>0.023925</td>\n",
       "      <td>-0.020274</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>-0.025815</td>\n",
       "      <td>0.056642</td>\n",
       "      <td>-0.054632</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>-0.028423</td>\n",
       "      <td>0.154924</td>\n",
       "      <td>-0.023442</td>\n",
       "      <td>0.030785</td>\n",
       "      <td>-0.009059</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>-0.057748</td>\n",
       "      <td>0.028850</td>\n",
       "      <td>-0.083053</td>\n",
       "      <td>0.027398</td>\n",
       "      <td>-0.021031</td>\n",
       "      <td>-0.019270</td>\n",
       "      <td>0.058161</td>\n",
       "      <td>-0.090327</td>\n",
       "      <td>-0.009771</td>\n",
       "      <td>-0.026482</td>\n",
       "      <td>0.042252</td>\n",
       "      <td>0.171135</td>\n",
       "      <td>0.162313</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>-0.023764</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>0.064079</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>-0.057553</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.020269</td>\n",
       "      <td>0.153049</td>\n",
       "      <td>0.043178</td>\n",
       "      <td>0.129189</td>\n",
       "      <td>0.102236</td>\n",
       "      <td>0.209509</td>\n",
       "      <td>0.094586</td>\n",
       "      <td>-0.071939</td>\n",
       "      <td>0.017253</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.018318</td>\n",
       "      <td>0.048879</td>\n",
       "      <td>-0.036259</td>\n",
       "      <td>-0.144544</td>\n",
       "      <td>0.141426</td>\n",
       "      <td>-0.059165</td>\n",
       "      <td>0.015180</td>\n",
       "      <td>0.085891</td>\n",
       "      <td>-0.061284</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>-0.006614</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.139115</td>\n",
       "      <td>-0.175368</td>\n",
       "      <td>-0.143780</td>\n",
       "      <td>-0.079759</td>\n",
       "      <td>-0.016045</td>\n",
       "      <td>0.042156</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>0.157571</td>\n",
       "      <td>-0.073194</td>\n",
       "      <td>0.132333</td>\n",
       "      <td>0.049896</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>0.072247</td>\n",
       "      <td>-0.102403</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>-0.024972</td>\n",
       "      <td>0.197308</td>\n",
       "      <td>-0.083250</td>\n",
       "      <td>0.083475</td>\n",
       "      <td>-0.038996</td>\n",
       "      <td>-0.123646</td>\n",
       "      <td>-0.111277</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>-0.002362</td>\n",
       "      <td>-0.038673</td>\n",
       "      <td>0.026627</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>-0.044917</td>\n",
       "      <td>-0.034327</td>\n",
       "      <td>-0.066516</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0.085812</td>\n",
       "      <td>-0.114901</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>-0.019880</td>\n",
       "      <td>0.015688</td>\n",
       "      <td>-0.162340</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>-0.316617</td>\n",
       "      <td>0.135379</td>\n",
       "      <td>0.060575</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>-0.145915</td>\n",
       "      <td>-0.253735</td>\n",
       "      <td>0.150593</td>\n",
       "      <td>-0.033289</td>\n",
       "      <td>0.139663</td>\n",
       "      <td>-0.054365</td>\n",
       "      <td>0.085324</td>\n",
       "      <td>-0.015820</td>\n",
       "      <td>-0.034635</td>\n",
       "      <td>0.042685</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>-0.037985</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>-0.102977</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.044481</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>-0.012425</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>-0.074231</td>\n",
       "      <td>-0.074419</td>\n",
       "      <td>0.074223</td>\n",
       "      <td>0.055457</td>\n",
       "      <td>-0.118381</td>\n",
       "      <td>-0.022631</td>\n",
       "      <td>-0.063968</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>-0.019164</td>\n",
       "      <td>-0.015749</td>\n",
       "      <td>-0.002252</td>\n",
       "      <td>-0.042219</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>-0.075391</td>\n",
       "      <td>-0.008808</td>\n",
       "      <td>-0.020212</td>\n",
       "      <td>0.121320</td>\n",
       "      <td>-0.002402</td>\n",
       "      <td>0.054313</td>\n",
       "      <td>0.026862</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>-0.018567</td>\n",
       "      <td>0.048477</td>\n",
       "      <td>-0.081590</td>\n",
       "      <td>0.028039</td>\n",
       "      <td>-0.031691</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.066822</td>\n",
       "      <td>-0.131549</td>\n",
       "      <td>0.032273</td>\n",
       "      <td>-0.024457</td>\n",
       "      <td>0.096930</td>\n",
       "      <td>0.168390</td>\n",
       "      <td>0.163072</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>-0.032681</td>\n",
       "      <td>0.108852</td>\n",
       "      <td>0.088763</td>\n",
       "      <td>-0.026153</td>\n",
       "      <td>0.071871</td>\n",
       "      <td>-0.036972</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.044825</td>\n",
       "      <td>0.144422</td>\n",
       "      <td>0.015192</td>\n",
       "      <td>0.115529</td>\n",
       "      <td>0.114808</td>\n",
       "      <td>0.219646</td>\n",
       "      <td>0.105310</td>\n",
       "      <td>-0.073234</td>\n",
       "      <td>-0.010100</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.026405</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>-0.002257</td>\n",
       "      <td>-0.145160</td>\n",
       "      <td>0.124852</td>\n",
       "      <td>-0.024557</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>-0.088154</td>\n",
       "      <td>-0.008780</td>\n",
       "      <td>0.029441</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.116295</td>\n",
       "      <td>0.110017</td>\n",
       "      <td>-0.167028</td>\n",
       "      <td>-0.153475</td>\n",
       "      <td>-0.113654</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>0.072149</td>\n",
       "      <td>0.147628</td>\n",
       "      <td>0.183239</td>\n",
       "      <td>-0.075399</td>\n",
       "      <td>0.149238</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>-0.090659</td>\n",
       "      <td>0.020279</td>\n",
       "      <td>-0.017666</td>\n",
       "      <td>0.180293</td>\n",
       "      <td>-0.079866</td>\n",
       "      <td>0.095523</td>\n",
       "      <td>-0.029783</td>\n",
       "      <td>-0.120660</td>\n",
       "      <td>-0.095879</td>\n",
       "      <td>0.098925</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>-0.073445</td>\n",
       "      <td>0.024101</td>\n",
       "      <td>0.119951</td>\n",
       "      <td>-0.080381</td>\n",
       "      <td>-0.043202</td>\n",
       "      <td>-0.055535</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>-0.108003</td>\n",
       "      <td>0.086189</td>\n",
       "      <td>-0.006190</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>-0.157865</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>0.017559</td>\n",
       "      <td>-0.323225</td>\n",
       "      <td>0.132554</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>0.025818</td>\n",
       "      <td>-0.132885</td>\n",
       "      <td>-0.251103</td>\n",
       "      <td>0.130839</td>\n",
       "      <td>-0.038164</td>\n",
       "      <td>0.126507</td>\n",
       "      <td>-0.058848</td>\n",
       "      <td>0.067926</td>\n",
       "      <td>-0.018180</td>\n",
       "      <td>-0.021153</td>\n",
       "      <td>0.041815</td>\n",
       "      <td>0.017218</td>\n",
       "      <td>-0.042574</td>\n",
       "      <td>-0.001439</td>\n",
       "      <td>-0.074991</td>\n",
       "      <td>0.060644</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>-0.004139</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>0.026320</td>\n",
       "      <td>-0.094264</td>\n",
       "      <td>-0.097984</td>\n",
       "      <td>0.085395</td>\n",
       "      <td>0.065912</td>\n",
       "      <td>-0.137885</td>\n",
       "      <td>-0.051900</td>\n",
       "      <td>-0.052750</td>\n",
       "      <td>-0.001735</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>-0.021617</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>-0.035426</td>\n",
       "      <td>0.052275</td>\n",
       "      <td>-0.061818</td>\n",
       "      <td>-0.010569</td>\n",
       "      <td>-0.023443</td>\n",
       "      <td>0.150068</td>\n",
       "      <td>-0.026663</td>\n",
       "      <td>0.047723</td>\n",
       "      <td>-0.005067</td>\n",
       "      <td>0.052954</td>\n",
       "      <td>-0.036659</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>-0.079995</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>-0.033588</td>\n",
       "      <td>-0.005425</td>\n",
       "      <td>0.060109</td>\n",
       "      <td>-0.103269</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.174294</td>\n",
       "      <td>0.153477</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>-0.021453</td>\n",
       "      <td>0.118568</td>\n",
       "      <td>0.063639</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>-0.061701</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "52  0.054610  0.104350 -0.004463  0.077184  0.084425  0.245455  0.116126   \n",
       "53  0.032987  0.163666  0.015800  0.111123  0.113665  0.212792  0.087295   \n",
       "54  0.043361  0.140201  0.027727  0.119405  0.110534  0.224276  0.097438   \n",
       "55  0.020269  0.153049  0.043178  0.129189  0.102236  0.209509  0.094586   \n",
       "56  0.044825  0.144422  0.015192  0.115529  0.114808  0.219646  0.105310   \n",
       "\n",
       "           7         8         9        10        11        12        13  \\\n",
       "52  0.000265  0.022170 -0.033977  0.041059  0.045683  0.042052 -0.185606   \n",
       "53 -0.095633 -0.009361  0.018600  0.021708  0.074333 -0.021175 -0.130598   \n",
       "54 -0.074569 -0.000330  0.003593  0.022222  0.069713 -0.009179 -0.153526   \n",
       "55 -0.071939  0.017253  0.009317  0.018318  0.048879 -0.036259 -0.144544   \n",
       "56 -0.073234 -0.010100  0.001178  0.026405  0.059387 -0.002257 -0.145160   \n",
       "\n",
       "          14        15        16        17        18        19        20  \\\n",
       "52  0.110666 -0.029643 -0.039188  0.066859 -0.137303 -0.008230  0.081344   \n",
       "53  0.118786 -0.033402  0.044143  0.101245 -0.056982 -0.024023  0.006679   \n",
       "54  0.124314 -0.013813  0.030834  0.097384 -0.082183 -0.024574  0.034190   \n",
       "55  0.141426 -0.059165  0.015180  0.085891 -0.061284 -0.033246  0.000353   \n",
       "56  0.124852 -0.024557  0.030683  0.096700 -0.088154 -0.008780  0.029441   \n",
       "\n",
       "          21        22        23        24        25        26        27  \\\n",
       "52  0.003713  0.018128  0.149097  0.065111 -0.200024 -0.145016 -0.179111   \n",
       "53  0.014928 -0.005566  0.109221  0.116470 -0.147236 -0.119256 -0.082188   \n",
       "54  0.017705 -0.000336  0.141087  0.110666 -0.162153 -0.136644 -0.121699   \n",
       "55 -0.006614  0.003030  0.099380  0.139115 -0.175368 -0.143780 -0.079759   \n",
       "56  0.003932  0.006262  0.116295  0.110017 -0.167028 -0.153475 -0.113654   \n",
       "\n",
       "          28        29        30        31        32        33        34  \\\n",
       "52 -0.026356  0.061489  0.149903  0.091268 -0.084600  0.146129  0.009054   \n",
       "53 -0.008614  0.084957  0.131567  0.177329 -0.059155  0.138054  0.044365   \n",
       "54 -0.010928  0.077683  0.148342  0.173177 -0.072420  0.145317  0.038170   \n",
       "55 -0.016045  0.042156  0.176985  0.157571 -0.073194  0.132333  0.049896   \n",
       "56 -0.005670  0.072149  0.147628  0.183239 -0.075399  0.149238  0.037534   \n",
       "\n",
       "          35        36        37        38        39        40        41  \\\n",
       "52  0.004619  0.057449 -0.098072 -0.020586  0.052420  0.181609 -0.089893   \n",
       "53  0.019384  0.086945 -0.108362  0.030022 -0.021587  0.175284 -0.084616   \n",
       "54  0.009872  0.078478 -0.105152  0.020973 -0.002050  0.180953 -0.078466   \n",
       "55  0.016715  0.072247 -0.102403  0.025302 -0.024972  0.197308 -0.083250   \n",
       "56  0.016809  0.074051 -0.090659  0.020279 -0.017666  0.180293 -0.079866   \n",
       "\n",
       "          42        43        44        45        46        47        48  \\\n",
       "52  0.045549  0.035239 -0.134608 -0.140755  0.096062 -0.009722 -0.046492   \n",
       "53  0.117992 -0.036376 -0.119377 -0.076172  0.107658 -0.005579 -0.072541   \n",
       "54  0.097529 -0.034858 -0.109210 -0.100710  0.102400 -0.012674 -0.066858   \n",
       "55  0.083475 -0.038996 -0.123646 -0.111277  0.067572 -0.002362 -0.038673   \n",
       "56  0.095523 -0.029783 -0.120660 -0.095879  0.098925  0.001434 -0.073445   \n",
       "\n",
       "          49        50        51        52        53        54        55  \\\n",
       "52  0.061963  0.101022 -0.151087 -0.073661 -0.022995 -0.010991  0.086426   \n",
       "53  0.019728  0.141467 -0.050046 -0.042476 -0.053328  0.026438  0.097934   \n",
       "54  0.014972  0.144579 -0.086460 -0.032010 -0.054449  0.014839  0.096662   \n",
       "55  0.026627  0.107994 -0.044917 -0.034327 -0.066516 -0.000393  0.085812   \n",
       "56  0.024101  0.119951 -0.080381 -0.043202 -0.055535  0.007263  0.086387   \n",
       "\n",
       "          56        57        58        59        60        61        62  \\\n",
       "52 -0.081251  0.092768  0.022553 -0.003308 -0.151577  0.015358  0.015049   \n",
       "53 -0.112352  0.078655 -0.016129  0.025090 -0.150243 -0.003288  0.022517   \n",
       "54 -0.093518  0.085893  0.001932  0.018282 -0.153094  0.006840  0.004288   \n",
       "55 -0.114901  0.065431 -0.019880  0.015688 -0.162340 -0.001200  0.003321   \n",
       "56 -0.108003  0.086189 -0.006190  0.017257 -0.157865  0.013116  0.017559   \n",
       "\n",
       "          63        64        65        66        67        68        69  \\\n",
       "52 -0.288440  0.084030 -0.045042  0.058321 -0.130605 -0.180030  0.067904   \n",
       "53 -0.325079  0.147143  0.033491  0.016758 -0.130750 -0.260288  0.164305   \n",
       "54 -0.326613  0.134978  0.022508  0.028558 -0.138046 -0.248304  0.132858   \n",
       "55 -0.316617  0.135379  0.060575  0.039270 -0.145915 -0.253735  0.150593   \n",
       "56 -0.323225  0.132554  0.037862  0.025818 -0.132885 -0.251103  0.130839   \n",
       "\n",
       "          70        71        72        73        74        75        76  \\\n",
       "52 -0.027518  0.127077 -0.050003  0.033541 -0.002756 -0.014882 -0.013859   \n",
       "53 -0.038398  0.119548 -0.070153  0.059296 -0.011169 -0.003433  0.056143   \n",
       "54 -0.043949  0.128050 -0.067901  0.051206 -0.011564 -0.005614  0.037196   \n",
       "55 -0.033289  0.139663 -0.054365  0.085324 -0.015820 -0.034635  0.042685   \n",
       "56 -0.038164  0.126507 -0.058848  0.067926 -0.018180 -0.021153  0.041815   \n",
       "\n",
       "          77        78        79        80        81        82        83  \\\n",
       "52  0.038555 -0.039611  0.073339 -0.052120  0.016868  0.035571  0.025171   \n",
       "53  0.030878 -0.047491 -0.030353 -0.083725  0.077166  0.037381  0.022413   \n",
       "54  0.031458 -0.046669  0.007304 -0.067419  0.067974  0.037900  0.012585   \n",
       "55  0.004028 -0.037985  0.005085 -0.102977  0.051758  0.044481  0.014813   \n",
       "56  0.017218 -0.042574 -0.001439 -0.074991  0.060644  0.023311  0.001310   \n",
       "\n",
       "          84        85        86        87        88        89        90  \\\n",
       "52 -0.033475  0.109169  0.074794 -0.116043 -0.124074  0.034347  0.043995   \n",
       "53  0.005073 -0.008114  0.017125 -0.086195 -0.082559  0.106784  0.041285   \n",
       "54 -0.000524  0.018387  0.035275 -0.097305 -0.114879  0.083355  0.040495   \n",
       "55  0.019356 -0.012425  0.021092 -0.074231 -0.074419  0.074223  0.055457   \n",
       "56 -0.004139  0.020462  0.026320 -0.094264 -0.097984  0.085395  0.065912   \n",
       "\n",
       "          91        92        93        94        95        96        97  \\\n",
       "52 -0.176807 -0.069833 -0.089236 -0.061160 -0.013047 -0.067469  0.001776   \n",
       "53 -0.136420 -0.042003 -0.041972  0.012694  0.010039 -0.005130  0.012509   \n",
       "54 -0.133043 -0.051679 -0.043090 -0.010320  0.023925 -0.020274  0.005864   \n",
       "55 -0.118381 -0.022631 -0.063968  0.009700 -0.019164 -0.015749 -0.002252   \n",
       "56 -0.137885 -0.051900 -0.052750 -0.001735  0.011231 -0.021617  0.011220   \n",
       "\n",
       "          98        99       100       101       102       103       104  \\\n",
       "52 -0.050246  0.084158 -0.054110 -0.028554 -0.002860  0.157867 -0.022253   \n",
       "53 -0.018407  0.038571 -0.065184  0.008954 -0.027177  0.141740 -0.026051   \n",
       "54 -0.025815  0.056642 -0.054632 -0.013899 -0.028423  0.154924 -0.023442   \n",
       "55 -0.042219  0.044484 -0.075391 -0.008808 -0.020212  0.121320 -0.002402   \n",
       "56 -0.035426  0.052275 -0.061818 -0.010569 -0.023443  0.150068 -0.026663   \n",
       "\n",
       "         105       106       107       108       109       110       111  \\\n",
       "52  0.012995 -0.048080  0.097035 -0.093582  0.030985 -0.077314  0.018657   \n",
       "53  0.048409 -0.002566  0.032745 -0.056513  0.029282 -0.075788  0.022865   \n",
       "54  0.030785 -0.009059  0.035124 -0.057748  0.028850 -0.083053  0.027398   \n",
       "55  0.054313  0.026862  0.036740 -0.018567  0.048477 -0.081590  0.028039   \n",
       "56  0.047723 -0.005067  0.052954 -0.036659  0.027947 -0.079995  0.033793   \n",
       "\n",
       "         112       113       114       115       116       117       118  \\\n",
       "52 -0.039799 -0.031165  0.000885 -0.018264 -0.008749 -0.011160  0.016747   \n",
       "53 -0.021595  0.004429  0.065029 -0.123813  0.017272 -0.043564  0.074258   \n",
       "54 -0.021031 -0.019270  0.058161 -0.090327 -0.009771 -0.026482  0.042252   \n",
       "55 -0.031691  0.005738  0.066822 -0.131549  0.032273 -0.024457  0.096930   \n",
       "56 -0.033588 -0.005425  0.060109 -0.103269  0.004462 -0.030550  0.064971   \n",
       "\n",
       "         119       120       121       122       123       124       125  \\\n",
       "52  0.171894  0.128862  0.002941 -0.054098  0.140353  0.029045 -0.037920   \n",
       "53  0.172774  0.173673  0.006066 -0.009477  0.092774  0.077578 -0.001269   \n",
       "54  0.171135  0.162313  0.013882 -0.023764  0.097157  0.064079  0.002145   \n",
       "55  0.168390  0.163072  0.016596 -0.032681  0.108852  0.088763 -0.026153   \n",
       "56  0.174294  0.153477  0.014282 -0.021453  0.118568  0.063639 -0.015721   \n",
       "\n",
       "         126       127  label  \n",
       "52 -0.035048 -0.009189      3  \n",
       "53  0.061320 -0.059570      3  \n",
       "54  0.028222 -0.057553      3  \n",
       "55  0.071871 -0.036972      3  \n",
       "56  0.038443 -0.061701      3  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp=pd.concat([df,y],axis=1)\n",
    "dfp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26649089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 129)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d81f51a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d442a1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      0,       1,       2,       3,       4,       5,       6,       7,\n",
       "             8,       9,\n",
       "       ...\n",
       "           119,     120,     121,     122,     123,     124,     125,     126,\n",
       "           127, 'label'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78475d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.iloc[:,-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a21a14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3b35e_row29_col1, #T_3b35e_row44_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3b35e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3b35e_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_3b35e_row0_col1\" class=\"data row0 col1\" >8793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3b35e_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_3b35e_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3b35e_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "      <td id=\"T_3b35e_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3b35e_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "      <td id=\"T_3b35e_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3b35e_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "      <td id=\"T_3b35e_row4_col1\" class=\"data row4 col1\" >(57, 129)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3b35e_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "      <td id=\"T_3b35e_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3b35e_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_3b35e_row6_col1\" class=\"data row6 col1\" >128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3b35e_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_3b35e_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3b35e_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_3b35e_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3b35e_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_3b35e_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3b35e_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_3b35e_row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3b35e_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_3b35e_row11_col1\" class=\"data row11 col1\" >(39, 128)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3b35e_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_3b35e_row12_col1\" class=\"data row12 col1\" >(18, 128)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3b35e_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_3b35e_row13_col1\" class=\"data row13 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3b35e_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_3b35e_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3b35e_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_3b35e_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3b35e_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_3b35e_row16_col1\" class=\"data row16 col1\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3b35e_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_3b35e_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3b35e_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_3b35e_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_3b35e_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_3b35e_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_3b35e_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_3b35e_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_3b35e_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_3b35e_row21_col1\" class=\"data row21 col1\" >e31d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_3b35e_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_3b35e_row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_3b35e_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_3b35e_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_3b35e_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_3b35e_row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_3b35e_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_3b35e_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_3b35e_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_3b35e_row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_3b35e_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_3b35e_row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_3b35e_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_3b35e_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_3b35e_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "      <td id=\"T_3b35e_row29_col1\" class=\"data row29 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_3b35e_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_3b35e_row30_col1\" class=\"data row30 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_3b35e_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "      <td id=\"T_3b35e_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_3b35e_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_3b35e_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_3b35e_row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "      <td id=\"T_3b35e_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_3b35e_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "      <td id=\"T_3b35e_row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_3b35e_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "      <td id=\"T_3b35e_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_3b35e_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_3b35e_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_3b35e_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_3b35e_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_3b35e_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_3b35e_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_3b35e_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_3b35e_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_3b35e_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_3b35e_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_3b35e_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_3b35e_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_3b35e_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_3b35e_row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_3b35e_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_3b35e_row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_3b35e_row44_col0\" class=\"data row44 col0\" >Remove Perfect Collinearity</td>\n",
       "      <td id=\"T_3b35e_row44_col1\" class=\"data row44 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_3b35e_row45_col0\" class=\"data row45 col0\" >Clustering</td>\n",
       "      <td id=\"T_3b35e_row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_3b35e_row46_col0\" class=\"data row46 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_3b35e_row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_3b35e_row47_col0\" class=\"data row47 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_3b35e_row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_3b35e_row48_col0\" class=\"data row48 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_3b35e_row48_col1\" class=\"data row48 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_3b35e_row49_col0\" class=\"data row49 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_3b35e_row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_3b35e_row50_col0\" class=\"data row50 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_3b35e_row50_col1\" class=\"data row50 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_3b35e_row51_col0\" class=\"data row51 col0\" >Group Features</td>\n",
       "      <td id=\"T_3b35e_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_3b35e_row52_col0\" class=\"data row52 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_3b35e_row52_col1\" class=\"data row52 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_3b35e_row53_col0\" class=\"data row53 col0\" >Feature Selection Method</td>\n",
       "      <td id=\"T_3b35e_row53_col1\" class=\"data row53 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_3b35e_row54_col0\" class=\"data row54 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_3b35e_row54_col1\" class=\"data row54 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_3b35e_row55_col0\" class=\"data row55 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_3b35e_row55_col1\" class=\"data row55 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_3b35e_row56_col0\" class=\"data row56 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_3b35e_row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_3b35e_row57_col0\" class=\"data row57 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_3b35e_row57_col1\" class=\"data row57 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_3b35e_row58_col0\" class=\"data row58 col0\" >Fix Imbalance</td>\n",
       "      <td id=\"T_3b35e_row58_col1\" class=\"data row58 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b35e_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_3b35e_row59_col0\" class=\"data row59 col0\" >Fix Imbalance Method</td>\n",
       "      <td id=\"T_3b35e_row59_col1\" class=\"data row59 col1\" >SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1926ddf72e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf=setup(data=dfp, target='label', normalize=True, normalize_method='zscore',data_split_shuffle=False,fold=12)\n",
    "# recognizer_model.fit(data[\"embeddings\"], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79dba032",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "442ec7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8d188_ th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8d188_row0_col0, #T_8d188_row1_col0, #T_8d188_row2_col0, #T_8d188_row3_col0, #T_8d188_row3_col2, #T_8d188_row4_col0, #T_8d188_row4_col2, #T_8d188_row5_col0, #T_8d188_row6_col0, #T_8d188_row7_col0, #T_8d188_row8_col0, #T_8d188_row9_col0, #T_8d188_row10_col0, #T_8d188_row10_col1, #T_8d188_row10_col2, #T_8d188_row10_col3, #T_8d188_row10_col4, #T_8d188_row10_col5, #T_8d188_row10_col6, #T_8d188_row10_col7, #T_8d188_row11_col0, #T_8d188_row11_col1, #T_8d188_row11_col2, #T_8d188_row11_col3, #T_8d188_row11_col4, #T_8d188_row11_col5, #T_8d188_row11_col6, #T_8d188_row11_col7, #T_8d188_row12_col0, #T_8d188_row12_col1, #T_8d188_row12_col2, #T_8d188_row12_col3, #T_8d188_row12_col4, #T_8d188_row12_col5, #T_8d188_row12_col6, #T_8d188_row12_col7, #T_8d188_row13_col0, #T_8d188_row13_col1, #T_8d188_row13_col2, #T_8d188_row13_col3, #T_8d188_row13_col4, #T_8d188_row13_col5, #T_8d188_row13_col6, #T_8d188_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8d188_row0_col1, #T_8d188_row0_col2, #T_8d188_row0_col3, #T_8d188_row0_col4, #T_8d188_row0_col5, #T_8d188_row0_col6, #T_8d188_row0_col7, #T_8d188_row1_col1, #T_8d188_row1_col2, #T_8d188_row1_col3, #T_8d188_row1_col4, #T_8d188_row1_col5, #T_8d188_row1_col6, #T_8d188_row1_col7, #T_8d188_row2_col1, #T_8d188_row2_col2, #T_8d188_row2_col3, #T_8d188_row2_col4, #T_8d188_row2_col5, #T_8d188_row2_col6, #T_8d188_row2_col7, #T_8d188_row3_col1, #T_8d188_row3_col3, #T_8d188_row3_col4, #T_8d188_row3_col5, #T_8d188_row3_col6, #T_8d188_row3_col7, #T_8d188_row4_col1, #T_8d188_row4_col3, #T_8d188_row4_col4, #T_8d188_row4_col5, #T_8d188_row4_col6, #T_8d188_row4_col7, #T_8d188_row5_col1, #T_8d188_row5_col2, #T_8d188_row5_col3, #T_8d188_row5_col4, #T_8d188_row5_col5, #T_8d188_row5_col6, #T_8d188_row5_col7, #T_8d188_row6_col1, #T_8d188_row6_col2, #T_8d188_row6_col3, #T_8d188_row6_col4, #T_8d188_row6_col5, #T_8d188_row6_col6, #T_8d188_row6_col7, #T_8d188_row7_col1, #T_8d188_row7_col2, #T_8d188_row7_col3, #T_8d188_row7_col4, #T_8d188_row7_col5, #T_8d188_row7_col6, #T_8d188_row7_col7, #T_8d188_row8_col1, #T_8d188_row8_col2, #T_8d188_row8_col3, #T_8d188_row8_col4, #T_8d188_row8_col5, #T_8d188_row8_col6, #T_8d188_row8_col7, #T_8d188_row9_col1, #T_8d188_row9_col2, #T_8d188_row9_col3, #T_8d188_row9_col4, #T_8d188_row9_col5, #T_8d188_row9_col6, #T_8d188_row9_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_8d188_row0_col8, #T_8d188_row1_col8, #T_8d188_row2_col8, #T_8d188_row3_col8, #T_8d188_row5_col8, #T_8d188_row6_col8, #T_8d188_row7_col8, #T_8d188_row8_col8, #T_8d188_row9_col8, #T_8d188_row10_col8, #T_8d188_row11_col8, #T_8d188_row12_col8, #T_8d188_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_8d188_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8d188_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_8d188_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_8d188_row0_col1\" class=\"data row0 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row0_col2\" class=\"data row0 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row0_col4\" class=\"data row0 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row0_col5\" class=\"data row0 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row0_col6\" class=\"data row0 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row0_col7\" class=\"data row0 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row0_col8\" class=\"data row0 col8\" >1.4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row1\" class=\"row_heading level0 row1\" >knn</th>\n",
       "      <td id=\"T_8d188_row1_col0\" class=\"data row1 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_8d188_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row1_col2\" class=\"data row1 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row1_col3\" class=\"data row1 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row1_col4\" class=\"data row1 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row1_col5\" class=\"data row1 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row1_col6\" class=\"data row1 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row1_col7\" class=\"data row1 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row1_col8\" class=\"data row1 col8\" >0.0242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row2\" class=\"row_heading level0 row2\" >nb</th>\n",
       "      <td id=\"T_8d188_row2_col0\" class=\"data row2 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_8d188_row2_col1\" class=\"data row2 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row2_col2\" class=\"data row2 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row2_col3\" class=\"data row2 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row2_col4\" class=\"data row2 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row2_col5\" class=\"data row2 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row2_col6\" class=\"data row2 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row2_col7\" class=\"data row2 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row2_col8\" class=\"data row2 col8\" >0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row3\" class=\"row_heading level0 row3\" >svm</th>\n",
       "      <td id=\"T_8d188_row3_col0\" class=\"data row3 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_8d188_row3_col1\" class=\"data row3 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_8d188_row3_col3\" class=\"data row3 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row3_col4\" class=\"data row3 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row3_col5\" class=\"data row3 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row3_col6\" class=\"data row3 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row3_col7\" class=\"data row3 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row3_col8\" class=\"data row3 col8\" >0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row4\" class=\"row_heading level0 row4\" >ridge</th>\n",
       "      <td id=\"T_8d188_row4_col0\" class=\"data row4 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_8d188_row4_col1\" class=\"data row4 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_8d188_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row4_col4\" class=\"data row4 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row4_col5\" class=\"data row4 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row4_col6\" class=\"data row4 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row4_col7\" class=\"data row4 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row4_col8\" class=\"data row4 col8\" >0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row5\" class=\"row_heading level0 row5\" >rf</th>\n",
       "      <td id=\"T_8d188_row5_col0\" class=\"data row5 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_8d188_row5_col1\" class=\"data row5 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row5_col2\" class=\"data row5 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row5_col4\" class=\"data row5 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row5_col5\" class=\"data row5 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row5_col6\" class=\"data row5 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row5_col7\" class=\"data row5 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row5_col8\" class=\"data row5 col8\" >0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_8d188_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_8d188_row6_col1\" class=\"data row6 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row6_col2\" class=\"data row6 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row6_col4\" class=\"data row6 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row6_col5\" class=\"data row6 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row6_col6\" class=\"data row6 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row6_col7\" class=\"data row6 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row6_col8\" class=\"data row6 col8\" >0.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row7\" class=\"row_heading level0 row7\" >gbc</th>\n",
       "      <td id=\"T_8d188_row7_col0\" class=\"data row7 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_8d188_row7_col1\" class=\"data row7 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row7_col2\" class=\"data row7 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row7_col4\" class=\"data row7 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row7_col5\" class=\"data row7 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row7_col6\" class=\"data row7 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row7_col7\" class=\"data row7 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row7_col8\" class=\"data row7 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_8d188_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_8d188_row8_col1\" class=\"data row8 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row8_col2\" class=\"data row8 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row8_col4\" class=\"data row8 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row8_col5\" class=\"data row8 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row8_col6\" class=\"data row8 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row8_col7\" class=\"data row8 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row8_col8\" class=\"data row8 col8\" >0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row9\" class=\"row_heading level0 row9\" >et</th>\n",
       "      <td id=\"T_8d188_row9_col0\" class=\"data row9 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_8d188_row9_col1\" class=\"data row9 col1\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row9_col2\" class=\"data row9 col2\" >0.7500</td>\n",
       "      <td id=\"T_8d188_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row9_col4\" class=\"data row9 col4\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row9_col5\" class=\"data row9 col5\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row9_col6\" class=\"data row9 col6\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row9_col7\" class=\"data row9 col7\" >1.0000</td>\n",
       "      <td id=\"T_8d188_row9_col8\" class=\"data row9 col8\" >0.1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_8d188_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_8d188_row10_col1\" class=\"data row10 col1\" >0.9583</td>\n",
       "      <td id=\"T_8d188_row10_col2\" class=\"data row10 col2\" >0.7153</td>\n",
       "      <td id=\"T_8d188_row10_col3\" class=\"data row10 col3\" >0.9444</td>\n",
       "      <td id=\"T_8d188_row10_col4\" class=\"data row10 col4\" >0.9340</td>\n",
       "      <td id=\"T_8d188_row10_col5\" class=\"data row10 col5\" >0.9431</td>\n",
       "      <td id=\"T_8d188_row10_col6\" class=\"data row10 col6\" >0.9296</td>\n",
       "      <td id=\"T_8d188_row10_col7\" class=\"data row10 col7\" >0.9430</td>\n",
       "      <td id=\"T_8d188_row10_col8\" class=\"data row10 col8\" >0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "      <td id=\"T_8d188_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_8d188_row11_col1\" class=\"data row11 col1\" >0.9167</td>\n",
       "      <td id=\"T_8d188_row11_col2\" class=\"data row11 col2\" >0.6875</td>\n",
       "      <td id=\"T_8d188_row11_col3\" class=\"data row11 col3\" >0.9167</td>\n",
       "      <td id=\"T_8d188_row11_col4\" class=\"data row11 col4\" >0.8750</td>\n",
       "      <td id=\"T_8d188_row11_col5\" class=\"data row11 col5\" >0.8889</td>\n",
       "      <td id=\"T_8d188_row11_col6\" class=\"data row11 col6\" >0.8750</td>\n",
       "      <td id=\"T_8d188_row11_col7\" class=\"data row11 col7\" >0.9031</td>\n",
       "      <td id=\"T_8d188_row11_col8\" class=\"data row11 col8\" >0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row12\" class=\"row_heading level0 row12\" >lightgbm</th>\n",
       "      <td id=\"T_8d188_row12_col0\" class=\"data row12 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_8d188_row12_col1\" class=\"data row12 col1\" >0.4306</td>\n",
       "      <td id=\"T_8d188_row12_col2\" class=\"data row12 col2\" >0.3750</td>\n",
       "      <td id=\"T_8d188_row12_col3\" class=\"data row12 col3\" >0.2500</td>\n",
       "      <td id=\"T_8d188_row12_col4\" class=\"data row12 col4\" >0.1181</td>\n",
       "      <td id=\"T_8d188_row12_col5\" class=\"data row12 col5\" >0.1667</td>\n",
       "      <td id=\"T_8d188_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_8d188_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_8d188_row12_col8\" class=\"data row12 col8\" >0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d188_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_8d188_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_8d188_row13_col1\" class=\"data row13 col1\" >0.4306</td>\n",
       "      <td id=\"T_8d188_row13_col2\" class=\"data row13 col2\" >0.3750</td>\n",
       "      <td id=\"T_8d188_row13_col3\" class=\"data row13 col3\" >0.2500</td>\n",
       "      <td id=\"T_8d188_row13_col4\" class=\"data row13 col4\" >0.1181</td>\n",
       "      <td id=\"T_8d188_row13_col5\" class=\"data row13 col5\" >0.1667</td>\n",
       "      <td id=\"T_8d188_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_8d188_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_8d188_row13_col8\" class=\"data row13 col8\" >0.0067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1926db708b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=compare_models(n_select=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "317afbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=8793, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                      weights='uniform'),\n",
       " GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
       "               power_t=0.5, random_state=8793, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                 max_iter=None, normalize=False, random_state=8793,\n",
       "                 solver='auto', tol=0.001),\n",
       " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=-1, oob_score=False, random_state=8793, verbose=0,\n",
       "                        warm_start=False),\n",
       " AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                    n_estimators=50, random_state=8793),\n",
       " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=8793, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                            solver='svd', store_covariance=False, tol=0.0001),\n",
       " ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                      criterion='gini', max_depth=None, max_features='auto',\n",
       "                      max_leaf_nodes=None, max_samples=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                      oob_score=False, random_state=8793, verbose=0,\n",
       "                      warm_start=False),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=8793, splitter='best'),\n",
       " QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "                               store_covariance=False, tol=0.0001),\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                random_state=8793, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "                subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       " DummyClassifier(constant=None, random_state=8793, strategy='prior')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b06b3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer_model = model #SVC(C=1.0, kernel=\"linear\", probability=True)\n",
    "recognizer_model.fit(data[\"embeddings\"], labels)\n",
    "\n",
    "# write the actual face recognition model to disk\n",
    "# f = open(args[\"recognizer\"], \"wb\")\n",
    "f = open(recognizer,\"wb\")\n",
    "f.write(pickle.dumps(recognizer_model))\n",
    "f.close()\n",
    "# write the label encoder to disk\n",
    "# f = open(args[\"le\"], \"wb\")\n",
    "f = open(le, \"wb\")\n",
    "f.write(pickle.dumps(label_encoder))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e8dfe75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9340</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.0267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.4306</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>0.4306</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "lr                    Logistic Regression    1.0000  0.7500  1.0000  1.0000   \n",
       "knn                K Neighbors Classifier    1.0000  0.7500  1.0000  1.0000   \n",
       "nb                            Naive Bayes    1.0000  0.7500  1.0000  1.0000   \n",
       "svm                   SVM - Linear Kernel    1.0000  0.0000  1.0000  1.0000   \n",
       "ridge                    Ridge Classifier    1.0000  0.0000  1.0000  1.0000   \n",
       "rf               Random Forest Classifier    1.0000  0.7500  1.0000  1.0000   \n",
       "ada                  Ada Boost Classifier    1.0000  0.7500  1.0000  1.0000   \n",
       "gbc          Gradient Boosting Classifier    1.0000  0.7500  1.0000  1.0000   \n",
       "lda          Linear Discriminant Analysis    1.0000  0.7500  1.0000  1.0000   \n",
       "et                 Extra Trees Classifier    1.0000  0.7500  1.0000  1.0000   \n",
       "dt               Decision Tree Classifier    0.9583  0.7153  0.9444  0.9340   \n",
       "qda       Quadratic Discriminant Analysis    0.9167  0.6875  0.9167  0.8750   \n",
       "lightgbm  Light Gradient Boosting Machine    0.4306  0.3750  0.2500  0.1181   \n",
       "dummy                    Dummy Classifier    0.4306  0.3750  0.2500  0.1181   \n",
       "\n",
       "              F1   Kappa     MCC  TT (Sec)  \n",
       "lr        1.0000  1.0000  1.0000    0.0317  \n",
       "knn       1.0000  1.0000  1.0000    0.0208  \n",
       "nb        1.0000  1.0000  1.0000    0.0342  \n",
       "svm       1.0000  1.0000  1.0000    0.0275  \n",
       "ridge     1.0000  1.0000  1.0000    0.0100  \n",
       "rf        1.0000  1.0000  1.0000    0.1392  \n",
       "ada       1.0000  1.0000  1.0000    0.0508  \n",
       "gbc       1.0000  1.0000  1.0000    0.1700  \n",
       "lda       1.0000  1.0000  1.0000    0.0133  \n",
       "et        1.0000  1.0000  1.0000    0.1258  \n",
       "dt        0.9431  0.9296  0.9430    0.0125  \n",
       "qda       0.8889  0.8750  0.9031    0.0267  \n",
       "lightgbm  0.1667  0.0000  0.0000    0.0308  \n",
       "dummy     0.1667  0.0000  0.0000    0.0125  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pull()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b37a777d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.loc['dt']['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "46d13068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4306"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m)\n",
    "m.iloc[len(m)-1]['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2f862562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=8793, splitter='best')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxscore=0\n",
    "argmaxscore=-1\n",
    "count=0\n",
    "for i in range(len(m)):\n",
    "    if i == n:\n",
    "        break\n",
    "    if m.iloc[i]['Accuracy']<1 and m.iloc[i]['Accuracy']>maxscore:\n",
    "        maxscore=m.iloc[i]['Accuracy']\n",
    "        argmaxscore=i\n",
    "print(argmaxscore)\n",
    "model[argmaxscore]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = setup(data=df, target='f1',data_split_shuffle=False,fold=12)\n",
    "# compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d0657b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bbc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8640b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76dd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305dd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
